{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:34:15.996463Z",
     "start_time": "2019-05-29T16:34:12.147934Z"
    }
   },
   "outputs": [],
   "source": [
    "# %run MyFunctions.ipynb\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import import_ipynb\n",
    "# import MyFunctions\n",
    "# from MyFunctions import *\n",
    "\n",
    "import datetime as dt\n",
    "import smtplib\n",
    "import simplejson\n",
    "import pymssql\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "# import datetime\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:34:16.010466Z",
     "start_time": "2019-05-29T16:34:16.000457Z"
    }
   },
   "outputs": [],
   "source": [
    "today = dt.datetime.today().strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T13:25:32.369621Z",
     "start_time": "2019-05-23T13:25:32.357658Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gh_df_v2():\n",
    "    \n",
    "    # generate gh credentials\n",
    "    with open(\"/Users/maxwell.lee/OneDrive - Jet/New Folder/Notebooks/Credentials/redshift_creds.json.nogit\") as fh:\n",
    "        creds_gh = simplejson.loads(fh.read())\n",
    "        \n",
    "    # generate gh query\n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/candidate_date_details_all_v2.sql', 'r')\n",
    "    sql_gh = file.read()\n",
    "    \n",
    "    #generate column lists\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/master_file_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/date_columns.txt') as f:\n",
    "        date_columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/time_columns.txt') as f:\n",
    "        time_columns = f.read().splitlines()      \n",
    "        \n",
    "    # connect to greenhouse\n",
    "    conn_red = psycopg2.connect(host = creds_gh['host_name'], \n",
    "                                port = creds_gh['port_num'], \n",
    "                                database = creds_gh['db_name'], \n",
    "                                user = creds_gh['user_name'],\n",
    "                                password = creds_gh['password'])\n",
    "    \n",
    "    # open cursor, run the query, fetch results, close cursor, close connection, save results to dataframe\n",
    "    cur = conn_red.cursor()\n",
    "    cur.execute(sql_gh)\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn_red.close()\n",
    "    df_gh = pd.DataFrame(results)\n",
    "    df_gh.columns = columns\n",
    "    \n",
    "    # convert datatypes\n",
    "    for cols in date_columns:\n",
    "        df_gh[cols] = pd.to_datetime(df_gh[cols], errors = 'coerce').dt.strftime('%m-%d-%Y').replace('NaT', '')\n",
    "    \n",
    "    return df_gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:34:18.544705Z",
     "start_time": "2019-05-29T16:34:18.529701Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_pdd_df_v2():\n",
    "    # generate pdd credentials\n",
    "    with open(\"/Users/maxwell.lee/OneDrive - Jet/New Folder/Notebooks/Credentials/sqlserver_creds.json.nogit\") as fh:\n",
    "        creds_pdd = simplejson.loads(fh.read())    \n",
    "        \n",
    "    # generate pdd query\n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/candidate_date_details_kenexa_v3.sql', 'r')\n",
    "    sql_pdd = file.read()\n",
    "    \n",
    "    #generate column lists\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/master_file_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/date_columns.txt') as f:\n",
    "        date_columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/time_columns.txt') as f:\n",
    "        time_columns = f.read().splitlines()\n",
    "        \n",
    "    # connect to pdd\n",
    "    conn_mssql = pymssql.connect(server = creds_pdd['server'],\n",
    "                                 user = creds_pdd['user_name'],\n",
    "                                 password = creds_pdd['password'])\n",
    "    \n",
    "    # open cursor, run the query, fetch results, close cursor, close connection, save results to dataframe\n",
    "    cur = conn_mssql.cursor()\n",
    "    cur.execute(sql_pdd)\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn_mssql.close()\n",
    "    df_pdd = pd.DataFrame(results)     \n",
    "    df_pdd.columns = columns\n",
    "\n",
    "    # convert datatypes\n",
    "    for cols in date_columns:\n",
    "        df_pdd[cols] = pd.to_datetime(df_pdd[cols], errors = 'coerce').dt.strftime('%m-%d-%Y').replace('NaT', '')\n",
    "    \n",
    "    return df_pdd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T13:25:34.205987Z",
     "start_time": "2019-05-23T13:25:34.197989Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_dataframes(df1, df2, df3):\n",
    "    \n",
    "    frames = [df1, df2]\n",
    "    df = pd.concat(frames)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df = pd.merge(df, df3, on = 'lookup_key', how = 'left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T14:13:54.071348Z",
     "start_time": "2019-05-23T14:13:54.050351Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_employee_lookup():\n",
    "    # generate pdd credentials\n",
    "    with open(\"/Users/maxwell.lee/OneDrive - Jet/New Folder/Notebooks/Credentials/sqlserver_creds.json.nogit\") as fh:\n",
    "        creds_pdd = simplejson.loads(fh.read())    \n",
    "        \n",
    "    # generate pdd query\n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/employee_lookup.sql', 'r')\n",
    "    sql_pdd = file.read()\n",
    "    \n",
    "    columns = ['lookup_key', 'job_effective_date', 'hire_date']\n",
    "    \n",
    "    # connect to pdd\n",
    "    conn_mssql = pymssql.connect(server = creds_pdd['server'],\n",
    "                                 user = creds_pdd['user_name'],\n",
    "                                 password = creds_pdd['password'])\n",
    "    \n",
    "    # open cursor, run the query, fetch results, close cursor, close connection, save results to dataframe\n",
    "    cur = conn_mssql.cursor()\n",
    "    cur.execute(sql_pdd)\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn_mssql.close()\n",
    "    df_pdd = pd.DataFrame(results)     \n",
    "    df_pdd.columns = columns\n",
    "    \n",
    "    df_pdd['job_effective_date'] = pd.to_datetime(df_pdd['job_effective_date'], errors = 'coerce').dt.strftime('%m-%d-%Y').replace('NaT', '')\n",
    "    df_pdd['hire_date'] = pd.to_datetime(df_pdd['hire_date'], errors = 'coerce').dt.strftime('%m-%d-%Y').replace('NaT', '')\n",
    "    \n",
    "    return df_pdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T14:13:54.108349Z",
     "start_time": "2019-05-23T14:13:54.078352Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_fills_report_v2(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/fills_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "    \n",
    "    df = dataframe\n",
    "    # drop all candidates with no offer_accepted_date\n",
    "    df = df[\n",
    "            (\n",
    "                (pd.to_datetime(df['anticipated_start_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "                |\n",
    "                (pd.to_datetime(df['job_effective_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "                |\n",
    "                (pd.to_datetime(df['hire_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "            )    \n",
    "            &\n",
    "            (\n",
    "                (pd.to_datetime(df['anticipated_start_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "                |\n",
    "                (pd.to_datetime(df['job_effective_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "                |\n",
    "                (pd.to_datetime(df['hire_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "            )\n",
    "            &\n",
    "            (df['offer_accepted_date'] != '')\n",
    "            &\n",
    "            (df['offer_declined_date'] == '')\n",
    "            & \n",
    "            (df['rejected_date'] == '')\n",
    "           ]\n",
    "    \n",
    "    df = df[columns]\n",
    "    df.to_excel('Fills_report_as_of_%s.xlsx' % file_date, index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:38:06.645568Z",
     "start_time": "2019-05-29T16:38:06.638582Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_fills_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/fills_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "    \n",
    "    df = dataframe\n",
    "    # drop all candidates with no offer_accepted_date\n",
    "    df = df[\n",
    "            (pd.to_datetime(df['anticipated_start_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "  \n",
    "            &\n",
    "            (pd.to_datetime(df['anticipated_start_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (df['offer_accepted_date'] != '')\n",
    "            &\n",
    "            (df['offer_declined_date'] == '')\n",
    "            & \n",
    "            (df['rejected_date'] == '')\n",
    "           ]\n",
    "    \n",
    "    df = df[columns]\n",
    "    df.to_excel('Custom_fills_report_as_of_%s.xlsx' % file_date, index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T13:25:39.182755Z",
     "start_time": "2019-05-23T13:25:39.173754Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_pending_offers_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/fills_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "\n",
    "    df = dataframe\n",
    "    # drop all candidates with null offer_extended_date\n",
    "    df = df[\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (df['offer_accepted_date'] == '')\n",
    "            &\n",
    "            (df['rejected_date'] == '')\n",
    "            &\n",
    "            (df['offer_declined_date'] == '')\n",
    "            &\n",
    "            (\n",
    "                (df['ta_current_status_mapped'] == 'Offer Extended') | \n",
    "                (df['ta_current_status_mapped'] == 'Hired') | \n",
    "                (df['ta_current_status_mapped'] == 'Offer Accepted') |\n",
    "                (df['ta_current_status_mapped'] == 'Selected')\n",
    "            )\n",
    "            &\n",
    "            ((df['job_status_mapped'] == 'Open') | (df['job_status_mapped'] == 'Hold'))\n",
    "           ]\n",
    "\n",
    "    df = df[columns]\n",
    "    df.to_excel('Pending_offers_report_as_of_%s.xlsx' % file_date, index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T13:25:39.382753Z",
     "start_time": "2019-05-23T13:25:39.375751Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_all_offers_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/all_offers_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "\n",
    "    df = dataframe\n",
    "    # drop all candidates with null offer_extended_date\n",
    "    df = df[\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "           ]\n",
    "\n",
    "    df = df[columns]\n",
    "    df.to_excel('All_offers_report_as_of_%s.xlsx' % file_date, index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T13:25:39.894752Z",
     "start_time": "2019-05-23T13:25:39.886749Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_opens_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/opens_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/opens_report.sql', 'r')\n",
    "    sql_opens_report = file.read()   \n",
    "        \n",
    "    sql_df = dataframe[columns]\n",
    "    \n",
    "    out = sqldf(sql_opens_report)\n",
    "    \n",
    "    out.to_excel('Opens_report_as_of_%s.xlsx' % file_date, index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:39:32.187027Z",
     "start_time": "2019-05-29T16:39:32.179031Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_open_funnel_report(dataframe, file_date):\n",
    "    \n",
    "    # import columns and sql query for report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/open_funnel_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/time_columns.txt') as f:\n",
    "        time_columns = f.read().splitlines()\n",
    "        \n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/open_funnels.sql', 'r')\n",
    "    sql_opens_report = file.read()\n",
    "    \n",
    "    # keep columns for report and handle data type issues\n",
    "    # sql_df = dataframe[columns]\n",
    "    \n",
    "    for cols in time_columns:\n",
    "        dataframe.loc[dataframe[cols].isnull(), cols] = -1\n",
    "        dataframe[cols] = dataframe[cols].astype(float)\n",
    "        #dataframe.loc[:, cols] = dataframe[cols].apply(lambda x: float(x))\n",
    "    \n",
    "    # generate report and write to excel\n",
    "    out = sqldf(sql_opens_report)\n",
    "    out.to_excel('Custom_open_funnels_report_as_of_%s.xlsx' % file_date, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T19:18:39.665342Z",
     "start_time": "2019-05-23T19:16:15.713319Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gh = generate_gh_df_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T17:29:45.445419Z",
     "start_time": "2019-05-29T17:28:56.316664Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pdd = generate_pdd_df_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T14:15:36.683205Z",
     "start_time": "2019-05-23T14:15:23.473916Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lookup = generate_employee_lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T14:16:44.527678Z",
     "start_time": "2019-05-23T14:15:36.683205Z"
    }
   },
   "outputs": [],
   "source": [
    "df = merge_dataframes(df_gh, df_pdd, df_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:38:29.703112Z",
     "start_time": "2019-05-29T16:38:29.091907Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_fills_report(df_pdd, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:39:19.613288Z",
     "start_time": "2019-05-29T16:39:17.400273Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_pending_offers_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-29fa4f307e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate_pending_offers_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_pending_offers_report' is not defined"
     ]
    }
   ],
   "source": [
    "generate_pending_offers_report(df_pdd, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T13:52:04.368893Z",
     "start_time": "2019-05-23T13:49:14.639009Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_opens_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T17:29:52.731136Z",
     "start_time": "2019-05-29T17:29:51.050136Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_open_funnel_report(df_pdd, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T14:13:54.045349Z",
     "start_time": "2019-05-23T14:13:43.102446Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_all_offers_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T17:30:05.676193Z",
     "start_time": "2019-05-29T17:29:52.736139Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pdd.to_excel('Custom_funnel_raw_%s.xlsx' % today, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
