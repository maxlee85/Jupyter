{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T14:00:58.465312Z",
     "start_time": "2019-05-30T14:00:57.793709Z"
    }
   },
   "outputs": [],
   "source": [
    "# %run MyFunctions.ipynb\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import import_ipynb\n",
    "# import MyFunctions\n",
    "# from MyFunctions import *\n",
    "\n",
    "import datetime as dt\n",
    "today = dt.datetime.today().strftime('%m-%d-%Y')\n",
    "import smtplib\n",
    "import simplejson\n",
    "import pymssql\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T14:00:59.238121Z",
     "start_time": "2019-05-30T14:00:59.224124Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gh_df_v2():\n",
    "    \n",
    "    # generate gh credentials\n",
    "    with open(\"/Users/maxwell.lee/OneDrive - Jet/New Folder/Notebooks/Credentials/redshift_creds.json.nogit\") as fh:\n",
    "        creds_gh = simplejson.loads(fh.read())\n",
    "        \n",
    "    # generate gh query\n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/candidate_date_details_all_v2.sql', 'r')\n",
    "    sql_gh = file.read()\n",
    "    \n",
    "    #generate column lists\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/master_file_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/date_columns.txt') as f:\n",
    "        date_columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/time_columns.txt') as f:\n",
    "        time_columns = f.read().splitlines()      \n",
    "        \n",
    "    # connect to greenhouse\n",
    "    conn_red = psycopg2.connect(host = creds_gh['host_name'], \n",
    "                                port = creds_gh['port_num'], \n",
    "                                database = creds_gh['db_name'], \n",
    "                                user = creds_gh['user_name'],\n",
    "                                password = creds_gh['password'])\n",
    "    \n",
    "    # open cursor, run the query, fetch results, close cursor, close connection, save results to dataframe\n",
    "    cur = conn_red.cursor()\n",
    "    cur.execute(sql_gh)\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn_red.close()\n",
    "    df_gh = pd.DataFrame(results)\n",
    "    df_gh.columns = columns\n",
    "    \n",
    "    # convert datatypes\n",
    "    for cols in date_columns:\n",
    "        df_gh[cols] = pd.to_datetime(df_gh[cols], errors = 'coerce').dt.strftime('%m-%d-%Y').replace('NaT', '')\n",
    "    \n",
    "    return df_gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T14:01:01.223546Z",
     "start_time": "2019-05-30T14:01:01.213547Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_pdd_df_v2():\n",
    "    # generate pdd credentials\n",
    "    with open(\"/Users/maxwell.lee/OneDrive - Jet/New Folder/Notebooks/Credentials/sqlserver_creds.json.nogit\") as fh:\n",
    "        creds_pdd = simplejson.loads(fh.read())    \n",
    "        \n",
    "    # generate pdd query\n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/candidate_date_details_kenexa_v2.sql', 'r')\n",
    "    sql_pdd = file.read()\n",
    "    \n",
    "    #generate column lists\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/master_file_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/date_columns.txt') as f:\n",
    "        date_columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/time_columns.txt') as f:\n",
    "        time_columns = f.read().splitlines()\n",
    "        \n",
    "    # connect to pdd\n",
    "    conn_mssql = pymssql.connect(server = creds_pdd['server'],\n",
    "                                 user = creds_pdd['user_name'],\n",
    "                                 password = creds_pdd['password'])\n",
    "    \n",
    "    # open cursor, run the query, fetch results, close cursor, close connection, save results to dataframe\n",
    "    cur = conn_mssql.cursor()\n",
    "    cur.execute(sql_pdd)\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn_mssql.close()\n",
    "    df_pdd = pd.DataFrame(results)     \n",
    "    df_pdd.columns = columns\n",
    "\n",
    "    # convert datatypes\n",
    "    for cols in date_columns:\n",
    "        df_pdd[cols] = pd.to_datetime(df_pdd[cols], errors = 'coerce').dt.strftime('%m-%d-%Y').replace('NaT', '')\n",
    "    \n",
    "    return df_pdd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T14:01:01.675256Z",
     "start_time": "2019-05-30T14:01:01.670298Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_dataframes(df1, df2):\n",
    "    \n",
    "    frames = [df1, df2]\n",
    "    df = pd.concat(frames)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T13:37:07.464203Z",
     "start_time": "2019-05-30T13:37:07.458189Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_fills_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/fills_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "    \n",
    "    df = dataframe\n",
    "    # drop all candidates with no offer_accepted_date\n",
    "    df = df[\n",
    "            (pd.to_datetime(df['anticipated_start_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (pd.to_datetime(df['anticipated_start_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (df['offer_accepted_date'] != '')\n",
    "            &\n",
    "            (df['offer_declined_date'] == '')\n",
    "            & \n",
    "            (df['rejected_date'] == '')\n",
    "           ]\n",
    "    \n",
    "    df = df[columns]\n",
    "    df.to_excel('Fills_report_as_of_%s.xlsx' % file_date, index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T13:37:08.085513Z",
     "start_time": "2019-05-30T13:37:08.078477Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_pending_offers_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/fills_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "\n",
    "    df = dataframe\n",
    "    # drop all candidates with null offer_extended_date\n",
    "    df = df[\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (df['offer_accepted_date'] == '')\n",
    "            &\n",
    "            (df['rejected_date'] == '')\n",
    "            &\n",
    "            (df['offer_declined_date'] == '')\n",
    "            &\n",
    "            (\n",
    "                (df['ta_current_status_mapped'] == 'Offer Extended') | \n",
    "                (df['ta_current_status_mapped'] == 'Hired') | \n",
    "                (df['ta_current_status_mapped'] == 'Offer Accepted') |\n",
    "                (df['ta_current_status_mapped'] == 'Selected')\n",
    "            )\n",
    "            &\n",
    "            ((df['job_status_mapped'] == 'Open') | (df['job_status_mapped'] == 'Hold'))\n",
    "           ]\n",
    "\n",
    "    df = df[columns]\n",
    "    df.to_excel('Pending_offers_report_as_of_%s.xlsx' % file_date, index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T13:37:08.472136Z",
     "start_time": "2019-05-30T13:37:08.462086Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_all_offers_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/all_offers_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "\n",
    "    df = dataframe\n",
    "    # drop all candidates with null offer_extended_date\n",
    "    df = df[\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') >= dt.datetime.strptime('2019-02-01', '%Y-%m-%d'))\n",
    "            &\n",
    "            (pd.to_datetime(df['offer_extended_date'], errors = 'coerce') < dt.datetime.strptime('2020-02-01', '%Y-%m-%d'))\n",
    "           ]\n",
    "\n",
    "    df = df[columns]\n",
    "    df.to_excel('All_offers_report_as_of_%s.xlsx' % file_date, index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T13:37:08.957702Z",
     "start_time": "2019-05-30T13:37:08.951203Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_opens_report(dataframe, file_date):\n",
    "    \n",
    "    # create new df, drop rows and write to excel\n",
    "    \n",
    "    # these are the columns used in this report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/opens_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/opens_report.sql', 'r')\n",
    "    sql_opens_report = file.read()   \n",
    "        \n",
    "    sql_df = dataframe[columns]\n",
    "    \n",
    "    out = sqldf(sql_opens_report)\n",
    "    \n",
    "    out.to_excel('Opens_report_as_of_%s.xlsx' % file_date, index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T13:37:09.517430Z",
     "start_time": "2019-05-30T13:37:09.507383Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_open_funnel_report(dataframe, file_date):\n",
    "    \n",
    "    # import columns and sql query for report\n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/open_funnel_report_columns.txt') as f:\n",
    "        columns = f.read().splitlines()\n",
    "        \n",
    "    with open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/time_columns.txt') as f:\n",
    "        time_columns = f.read().splitlines()\n",
    "        \n",
    "    file = open('/Users/maxwell.lee/OneDrive - Jet/New Folder/Queries/open_funnels.sql', 'r')\n",
    "    sql_opens_report = file.read()\n",
    "    \n",
    "    # keep columns for report and handle data type issues\n",
    "    # sql_df = dataframe[columns]\n",
    "    \n",
    "    for cols in time_columns:\n",
    "        dataframe.loc[dataframe[cols].isnull(), cols] = -1\n",
    "        dataframe[cols] = dataframe[cols].astype(float)\n",
    "        #dataframe.loc[:, cols] = dataframe[cols].apply(lambda x: float(x))\n",
    "    \n",
    "    # generate report and write to excel\n",
    "    out = sqldf(sql_opens_report)\n",
    "    out.to_excel('Open_funnels_report_as_of_%s.xlsx' % file_date, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T14:09:27.662834Z",
     "start_time": "2019-05-30T14:01:05.253945Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gh = generate_gh_df_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-30T14:01:05.486Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pdd = generate_pdd_df_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-30T14:01:05.691Z"
    }
   },
   "outputs": [],
   "source": [
    "df = merge_dataframes(df_gh, df_pdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-30T14:58:46.225Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_fills_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T14:11:54.870819Z",
     "start_time": "2019-05-29T14:11:16.230124Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_pending_offers_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T14:24:10.315417Z",
     "start_time": "2019-05-29T14:11:54.888864Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_opens_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:29:16.747733Z",
     "start_time": "2019-05-29T14:24:10.325417Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_open_funnel_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:29:26.718953Z",
     "start_time": "2019-05-29T15:29:16.793735Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_all_offers_report(df, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
